# Generating-Text
## 使用方式
## 本项目中用到的模型
* word2vec/doc2vec [1],[2]
* CNN [[3](#[3])]
* SVM [4]
* BILSTM+maxpooling[5]

## 不同深度学习模型分类性能对比
我们选择ubuntu操作系统作为测试环境,对传统的SVM模型和CNN等深度学习模型进行了效果对比，测试机的配置为：AMDA4-7300APU
我们的测试数据包含５０W篇文本（其中有7000篇有人工标记的label，其余为无标注的文本）,其中7000篇作文按照４：1的比例分为
training和test，random seed 为1337.以下是目前的测试结果：
### 生成文本：
| Input                 | Precison      |    Recall    |  F-Measure   | settings                                  |
|:-------------------------:|:-------------:|:------------:|:------------:|:-----------------------------------------:|
|docvec+title+LDA+SVM       |0.801155292901 |0.803142857143|0.802147843826|128D doc2vec+128D title-word2vec+100D LDA  |
|docvec+SVM                 |0.729639110528 |0.733142857143|0.731386787639|128D doc2vec                               |
|word2vec+CNN               |0.671994335198 |0.653571428571|0.662654859761|128D word2vec                              |
|word2vec+SimpleRNN         |0.480495854176 |0.477857142857|0.479172865827|128D word2vec                              |
|word2vec+LSTM              |0.646029423882 |0.641428571429|0.643720776866|128D word2vec                              |

### 生成的模板：
| Input                 | Precison      |    Recall    |  F-Measure   | settings                                  |
|:-------------------------:|:-------------:|:------------:|:------------:|:-----------------------------------------:|
|docvec+title+LDA+SVM       |0.801155292901 |0.803142857143|0.802147843826|128D doc2vec+128D title-word2vec+100D LDA  |
|docvec+SVM                 |0.729639110528 |0.733142857143|0.731386787639|128D doc2vec                               |
|word2vec+CNN               |0.671994335198 |0.653571428571|0.662654859761|128D word2vec                              |
|word2vec+SimpleRNN         |0.480495854176 |0.477857142857|0.479172865827|128D word2vec                              |
|word2vec+LSTM              |0.646029423882 |0.641428571429|0.643720776866|128D word2vec                              |
